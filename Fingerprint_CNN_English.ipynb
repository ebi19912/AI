{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAeJ1zEHHTUU8PnSQq+d0+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebi19912/AI/blob/main/Fingerprint_CNN_English.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Here is a more detailed explanation of each line of code:"
      ],
      "metadata": {
        "id": "ZWmE6xNJw69G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afpKwuBZwwNw"
      },
      "outputs": [],
      "source": [
        "# Install the Kaggle library\n",
        "!pip install kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the Kaggle.json file\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "id": "VIZMQbyaxSxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line of code uses the files module to upload the Kaggle.json file to the Google Colab environment. The Kaggle.json file is a file that contains your Kaggle API credentials. You can create a Kaggle account and generate your API credentials on the Kaggle website."
      ],
      "metadata": {
        "id": "72ILmrsDxcWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the Kaggle API\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "7SEbFUo4xy_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These three lines of code set up the Kaggle API. The first line of code creates a directory called ~/.kaggle in the home directory. The second line of code copies the Kaggle.json file to the ~/.kaggle directory. The third line of code changes the permissions on the Kaggle.json file to 600. This ensures that only the owner of the file can access it."
      ],
      "metadata": {
        "id": "D_kR2EXbx2VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the fingerprint dataset\n",
        "!kaggle datasets download -d peace1019/fingerprint-dataset-for-fvc2000-db4-b\n"
      ],
      "metadata": {
        "id": "FQOqJETPx6fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line of code downloads the fingerprint dataset from Kaggle. The dataset is downloaded to the current working directory."
      ],
      "metadata": {
        "id": "5pvrNjJ0x9wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the files from the compressed file\n",
        "import zipfile\n",
        "with zipfile.ZipFile('fingerprint-dataset-for-fvc2000-db4-b.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')\n"
      ],
      "metadata": {
        "id": "Jw-IOdxEyEIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two lines of code extract the files from the compressed file. The compressed file is called \"fingerprint-dataset-for-fvc2000-db4-b.zip\". The extracted files are placed in a directory called \"dataset\"."
      ],
      "metadata": {
        "id": "w0pcGkkvyITX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import models, layers"
      ],
      "metadata": {
        "id": "9SpWmACB0C9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to load images from a folder\n",
        "def load_images_from_folder(folder):\n",
        "\n",
        "  # Create empty lists to store the images and labels\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  # Iterate over all of the files in the folder\n",
        "  for filename in os.listdir(folder):\n",
        "\n",
        "    # Read the image into memory\n",
        "    img = cv2.imread(os.path.join(folder,filename), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Check to make sure that the image is not None\n",
        "    if img is not None:\n",
        "\n",
        "      # Add the image and label to the corresponding lists\n",
        "      images.append(img)\n",
        "      labels.append(int(filename.split('_')[0].split('.')[0]))\n",
        "\n",
        "  # Return the images and labels\n",
        "  return images, labels\n",
        "\n",
        "# Load the training and test datasets\n",
        "x_train, y_train = load_images_from_folder('/content/dataset/dataset_FVC2000_DB4_B/dataset/train_data')\n",
        "x_test, y_test = load_images_from_folder('/content/dataset/dataset_FVC2000_DB4_B/dataset/real_data')\n",
        "\n",
        "# Print the number of training images and the shape of the first training image\n",
        "print(\"Number of training images:\", len(x_train))\n",
        "print(\"Shape of the first training image:\", x_train[0].shape)\n"
      ],
      "metadata": {
        "id": "_bZViXmz0Saz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The first function, load_images_from_folder(), loads all of the images in a given folder and their corresponding labels. The function takes a single argument, which is the path to the folder containing the images. The function returns two lists: images and labels. The images list contains all of the images in the folder, and the labels list contains the corresponding labels for each image.\n",
        "\n",
        "The function works by first iterating over all of the files in the folder. For each file, the function uses the cv2.imread() function to read the image into memory. The function then checks to make sure that the image is not None. If the image is not None, the function adds it to the images list and the corresponding label to the labels list.\n",
        "\n",
        "The second part of the code loads the training and test datasets using the load_images_from_folder() function. The function first loads the training dataset from the /content/dataset/dataset_FVC2000_DB4_B/dataset/train_data folder. The function then loads the test dataset from the /content/dataset/dataset_FVC2000_DB4_B/dataset/real_data folder.\n",
        "\n",
        "Finally, the code prints the number of training images and the shape of the first training image."
      ],
      "metadata": {
        "id": "bYtbbE6T0UFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the list of training images to a NumPy array\n",
        "x_train = np.array(x_train).reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "\n",
        "# Convert the list of test images to a NumPy array\n",
        "x_test = np.array(x_test).reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "\n",
        "# Convert the list of training labels to one-hot format\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "# Convert the list of test labels to one-hot format\n",
        "y_test = to_categorical(y_test)\n"
      ],
      "metadata": {
        "id": "O8FS-0dv0nmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code you provided converts the lists of images and labels to NumPy arrays and normalizes the images. It also converts the labels to one-hot format.\n",
        "\n",
        "The first line of code converts the list of training images to a NumPy array. The reshape() function is used to change the shape of the array to (-1, 160, 160, 1). The -1 in the first dimension indicates that the array should be automatically resized to fit the other dimensions. The astype() function is used to convert the array to the float32 data type. The /255.0 operation normalizes the images to the range [0, 1].\n",
        "\n",
        "The second line of code converts the list of test images to a NumPy array. The code is the same as the code for the training images.\n",
        "\n",
        "The third line of code converts the list of training labels to one-hot format. The to_categorical() function is used to do this. The one-hot format is a way of representing categorical data as a vector. In this case, each label is represented as a vector with 10 elements. The element at index i is 1 if the label is i, and 0 otherwise.\n",
        "\n",
        "The fourth line of code converts the list of test labels to one-hot format. The code is the same as the code for the training labels."
      ],
      "metadata": {
        "id": "WEdmbjtb031e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sequential model\n",
        "model = models.Sequential()\n",
        "\n",
        "# Add a convolutional layer with 32 filters of size 3x3\n",
        "model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(160, 160, 1)))\n",
        "\n",
        "# Add a max pooling layer with a pooling size of 2x2\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Add another convolutional layer with 64 filters of size 3x3\n",
        "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "\n",
        "# Add another max pooling layer with a pooling size of 2x2\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the output of the previous layer\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Add a dense layer with 128 neurons\n",
        "model.add(layers.Dense(128, activation=\"relu\"))\n",
        "\n",
        "# Add a dense layer with 10 neurons, one for each fingerprint class\n",
        "model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compile the model using the Adam optimizer and the categorical cross-entropy loss function\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model for 10 epochs on the training dataset\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate the model on the test dataset and print the test loss and test accuracy\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n"
      ],
      "metadata": {
        "id": "SzrkVTyv0_Do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "provided creates a convolutional neural network (CNN) model and trains it to classify fingerprint images. The CNN model has the following architecture:\n",
        "\n",
        "Convolutional layer 1: This layer has 32 filters, each of which is 3x3 pixels in size. The activation function for this layer is ReLU.\n",
        "Max pooling layer 1: This layer downsamples the input by a factor of 2 in both the width and height dimensions.\n",
        "Convolutional layer 2: This layer has 64 filters, each of which is 3x3 pixels in size. The activation function for this layer is ReLU.\n",
        "Max pooling layer 2: This layer downsamples the input by a factor of 2 in both the width and height dimensions.\n",
        "Flatten layer: This layer flattens the output of the previous layer into a one-dimensional vector.\n",
        "Dense layer 1: This layer has 128 neurons. The activation function for this layer is ReLU.\n",
        "Dense layer 2: This layer has 10 neurons, one for each fingerprint class. The activation function for this layer is softmax.\n",
        "The code then compiles the model using the Adam optimizer and the categorical cross-entropy loss function. The model is then trained for 10 epochs on the training dataset.\n",
        "\n",
        "Finally, the code evaluates the model on the test dataset and prints the test loss and test accuracy."
      ],
      "metadata": {
        "id": "4YBeOicY1J-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib\n",
        "import joblib"
      ],
      "metadata": {
        "id": "ao8FOi551QBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register a fingerprint\n",
        "def register_fingerprint(image):\n",
        "\n",
        "    # Pre-process the image\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = cv2.resize(image, (160, 160))\n",
        "    image = image.reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "\n",
        "    # Predict the fingerprint features\n",
        "    features = model.predict(image)\n",
        "\n",
        "    # Save the features\n",
        "    features = features.flatten()\n",
        "    with open('fingerprint_features.pickle', 'wb') as f:\n",
        "        joblib.dump(features, f)\n",
        "\n",
        "# Authenticate a fingerprint\n",
        "def authenticate_fingerprint(image):\n",
        "\n",
        "    # Pre-process the image\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = cv2.resize(image, (160, 160))\n",
        "    image = image.reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "\n",
        "    # Predict the fingerprint features\n",
        "    features = model.predict(image)\n",
        "\n",
        "    # Compare the features\n",
        "    with open('fingerprint_features.pickle', 'rb') as f:\n",
        "        known_features = joblib.load(f)\n",
        "\n",
        "    # Use the distance function to compare the features\n",
        "    dist = np.linalg.norm(features - known_features, axis=1)\n",
        "\n",
        "    # Authentication result\n",
        "    if dist < 0.01:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "BmtfRP2A1V3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The register_fingerprint() function takes an image as input and registers the fingerprint features for that image. The function first pre-processes the image by converting it to grayscale, resizing it to 160x160 pixels, and normalizing it to the range [0, 1]. The function then predicts the fingerprint features using the trained CNN model. Finally, the function saves the fingerprint features to a file called fingerprint_features.pickle.\n",
        "\n",
        "The authenticate_fingerprint() function takes an image as input and authenticates the fingerprint by comparing it to the fingerprint features stored in the fingerprint_features.pickle file. The function first pre-processes the image the same way as the register_fingerprint() function. The function then predicts the fingerprint features for the input image. The function then compares the fingerprint features for the input image to the fingerprint features stored in the file. The function returns True if the distance between the two sets of features is less than a threshold of 0.01. Otherwise, the function returns False."
      ],
      "metadata": {
        "id": "9Wwm6seb1k7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fingerprint image\n",
        "image = cv2.imread('FingerPrintOriginal.jpg')\n",
        "\n",
        "# Register the fingerprint features\n",
        "register_fingerprint(image)\n",
        "\n",
        "# Authenticate the fingerprint\n",
        "is_authenticated = authenticate_fingerprint(image)\n",
        "\n",
        "# Print the authentication result\n",
        "print(is_authenticated)\n"
      ],
      "metadata": {
        "id": "RxDfN-FO1rOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "first loads the image FingerPrintOriginal.jpg into memory using the cv2.imread() function. The code then calls the register_fingerprint() function to register the fingerprint features for the image.\n",
        "\n",
        "Next, the code loads the same image again and calls the authenticate_fingerprint() function to authenticate the fingerprint. The code then prints the result of the authentication to the console.\n",
        "\n",
        "If the fingerprint is authenticated successfully, the code will print True. Otherwise, the code will print False."
      ],
      "metadata": {
        "id": "epg4Ghkb1zct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is a good example of how to use a trained CNN model to perform fingerprint registration and authentication."
      ],
      "metadata": {
        "id": "x_x510Rb1-GK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Love !\n",
        "linkedin.com/in/rouhalah-ebrahimi/"
      ],
      "metadata": {
        "id": "1BgKTGw52C6-"
      }
    }
  ]
}
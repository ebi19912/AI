{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLeCT+gTwZ3xvMr5Qe7Xq2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebi19912/AI/blob/main/Fingerprint_CNN_Persian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# نصب کتابخانه kaggle\n",
        "!pip install kaggle\n",
        "\n",
        "# آپلود فایل kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# تنظیمات مربوط به فایل kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# دانلود مجموعه داده از Kaggle\n",
        "!kaggle datasets download -d peace1019/fingerprint-dataset-for-fvc2000-db4-b\n",
        "\n",
        "# استخراج فایل‌ها از فایل فشرده\n",
        "import zipfile\n",
        "with zipfile.ZipFile('fingerprint-dataset-for-fvc2000-db4-b.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')\n"
      ],
      "metadata": {
        "id": "pP32IAsAvSSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import models, layers"
      ],
      "metadata": {
        "id": "tvT2uQGHvj-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# بارگیری و پردازش تصاویر\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "            labels.append(int(filename.split('_')[0].split('.')[0]))  # استخراج برچسب از نام فایل\n",
        "    return images, labels\n",
        "\n",
        "x_train, y_train = load_images_from_folder('/content/dataset/dataset_FVC2000_DB4_B/dataset/train_data')\n",
        "x_test, y_test = load_images_from_folder('/content/dataset/dataset_FVC2000_DB4_B/dataset/real_data')\n",
        "\n",
        "print(\"Number of training images:\", len(x_train))\n",
        "print(\"Shape of the first training image:\", x_train[0].shape)\n"
      ],
      "metadata": {
        "id": "m6YuFqXovzRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# تبدیل لیست‌ها به آرایه‌های numpy و نرمال‌سازی\n",
        "x_train = np.array(x_train).reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "x_test = np.array(x_test).reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "\n",
        "\n",
        "# تبدیل برچسب‌ها به فرمت one-hot\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n"
      ],
      "metadata": {
        "id": "XKjn3bBzv2nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amXVCwWxFABl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ایجاد شبکه عصبی\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(160, 160, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "\n",
        "# آموزش شبکه عصبی\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# ارزیابی شبکه عصبی\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib\n",
        "import joblib"
      ],
      "metadata": {
        "id": "ok9m1r5Qy5mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ثبت اثر انگشت\n",
        "def register_fingerprint(image):\n",
        "    # پیش پردازش تصویر\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = cv2.resize(image, (160, 160))\n",
        "    image = image.reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "\n",
        "    # پیش بینی ویژگی‌های اثر انگشت\n",
        "    features = model.predict(image)\n",
        "\n",
        "    # ذخیره ویژگی‌ها\n",
        "    features = features.flatten()\n",
        "    with open('fingerprint_features.pickle', 'wb') as f:\n",
        "        joblib.dump(features, f)\n",
        "\n",
        "# احراز هویت اثر انگشت\n",
        "def authenticate_fingerprint(image):\n",
        "    # پیش پردازش تصویر\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = cv2.resize(image, (160, 160))\n",
        "    image = image.reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "\n",
        "    # پیش بینی ویژگی‌های اثر انگشت\n",
        "    features = model.predict(image)\n",
        "\n",
        "    # مقایسه ویژگی‌ها\n",
        "    with open('fingerprint_features.pickle', 'rb') as f:\n",
        "        known_features = joblib.load(f)\n",
        "\n",
        "    # استفاده از تابع فاصله برای مقایسه ویژگی‌ها\n",
        "    dist = np.linalg.norm(features - known_features, axis=1)\n",
        "\n",
        "    # نتیجه احراز هویت\n",
        "    if dist < 0.01:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "XfribNlhyDKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ثبت اثر انگشت\n",
        "image = cv2.imread('FingerPrintOriginal.jpg')\n",
        "register_fingerprint(image)\n",
        "\n",
        "# احراز هویت اثر انگشت\n",
        "image = cv2.imread('FingerPrintOriginal.jpg')\n",
        "is_authenticated = authenticate_fingerprint(image)\n",
        "print(is_authenticated)\n"
      ],
      "metadata": {
        "id": "1n-10Ah7wQ5h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
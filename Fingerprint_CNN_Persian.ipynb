{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPO9cVM7/4ffYV+8hF3VmUc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebi19912/AI/blob/main/Fingerprint_CNN_Persian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# نصب کتابخانه kaggle\n",
        "!pip install kaggle\n",
        "\n",
        "# آپلود فایل kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# تنظیمات مربوط به فایل kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# دانلود مجموعه داده از Kaggle\n",
        "!kaggle datasets download -d peace1019/fingerprint-dataset-for-fvc2000-db4-b\n",
        "\n",
        "# استخراج فایل‌ها از فایل فشرده\n",
        "import zipfile\n",
        "with zipfile.ZipFile('fingerprint-dataset-for-fvc2000-db4-b.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')\n"
      ],
      "metadata": {
        "id": "fiCitMD_4HBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# نصب کتابخانه kaggle\n",
        "!pip install kaggle\n",
        "\n",
        "# آپلود فایل kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# تنظیمات مربوط به فایل kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# دانلود مجموعه داده از Kaggle\n",
        "!kaggle datasets download -d peace1019/fingerprint-dataset-for-fvc2000-db4-b\n",
        "\n",
        "# استخراج فایل‌ها از فایل فشرده\n",
        "import zipfile\n",
        "with zipfile.ZipFile('fingerprint-dataset-for-fvc2000-db4-b.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')\n"
      ],
      "metadata": {
        "id": "pP32IAsAvSSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import models, layers"
      ],
      "metadata": {
        "id": "tvT2uQGHvj-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "تابع load_images_from_folder() مجموعه ای از تصاویر را از یک پوشه بارگیری می کند و یک لیست از تصاویر و یک لیست از برچسب ها را برمی گرداند. تابع در پوشه تکرار می شود و هر تصویر را با استفاده از تابع cv2.imread() بارگیری می کند. تابع همچنین برچسب هر تصویر را از نام فایل استخراج می کند. برچسب ها در یک لیست ذخیره می شوند.\n",
        "\n",
        "توضیحات:\n",
        "\n",
        "خط 1: تابع load_images_from_folder() تعریف می شود.\n",
        "\n",
        "خط 2: یک لیست خالی برای ذخیره تصاویر ایجاد می شود.\n",
        "\n",
        "خط 3: یک لیست خالی برای ذخیره برچسب ها ایجاد می شود.\n",
        "\n",
        "خط 4: تابع os.listdir() برای دریافت لیست تمام فایل ها در پوشه مشخص شده استفاده می شود.\n",
        "\n",
        "خط 5: تابع cv2.imread() برای بارگیری تصویر در مسیر مشخص شده استفاده می شود.\n",
        "\n",
        "خط 6: عبارت if بررسی می کند که تصویر None نیست. اگر اینطور نیست، تصویر و برچسب به لیست های مربوطه اضافه می شوند.\n",
        "\n",
        "خط 7: برچسب از نام فایل استخراج می شود. نام فایل بر روی کاراکتر '_' تقسیم می شود و اولین عنصر گرفته می شود. این عنصر سپس به یک عدد صحیح تبدیل می شود.\n",
        "\n",
        "خط 8: عبارت return لیست های تصاویر و برچسب ها را برمی گرداند.\n",
        "\n"
      ],
      "metadata": {
        "id": "MhgSi_fw4r5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# بارگیری و پردازش تصاویر\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "            labels.append(int(filename.split('_')[0].split('.')[0]))  # استخراج برچسب از نام فایل\n",
        "    return images, labels\n",
        "\n",
        "x_train, y_train = load_images_from_folder('/content/dataset/dataset_FVC2000_DB4_B/dataset/train_data')\n",
        "x_test, y_test = load_images_from_folder('/content/dataset/dataset_FVC2000_DB4_B/dataset/real_data')\n",
        "\n",
        "print(\"Number of training images:\", len(x_train))\n",
        "print(\"Shape of the first training image:\", x_train[0].shape)\n"
      ],
      "metadata": {
        "id": "m6YuFqXovzRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "این کد دو عملیات را انجام می دهد:\n",
        "\n",
        "تبدیل لیست های تصاویر و برچسب ها به آرایه های NumPy\n",
        "نرمال سازی تصاویر\n",
        "تبدیل لیست ها به آرایه های NumPy:\n",
        "\n",
        "تابع np.array() یک لیست را به یک آرایه NumPy تبدیل می کند. پارامتر -1 به تابع np.array() می گوید که تعداد ردیف ها را خود محاسبه کند.\n",
        "\n",
        "نرمال سازی تصاویر:\n",
        "\n",
        "تصاویر را می توان با تقسیم آنها بر 255.0 نرمال کرد. این کار باعث می شود که تمام مقادیر تصویر بین 0 و 1 قرار گیرند.\n",
        "\n",
        "تبدیل برچسب ها به فرمت one-hot:\n",
        "\n",
        "برچسب ها در مجموعه داده اثر انگشت FVC2000 DB4B اعداد صحیح هستند. برای استفاده از یک مدل شبکه عصبی، باید برچسب ها را به فرمت one-hot تبدیل کرد.\n",
        "\n",
        "تابع to_categorical() یک آرایه از برچسب ها را به یک آرایه one-hot تبدیل می کند. در این مورد، هر برچسب به یک آرایه 10 بعدی تبدیل می شود که تنها عنصر غیر صفر آن در موقعیت برچسب مربوطه قرار دارد.\n",
        "\n",
        "مثال:\n",
        "\n",
        "فرض کنید لیست y_train حاوی برچسب های زیر باشد:\n",
        "\n",
        "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "پس از اجرای کد زیر، لیست y_train به آرایه زیر تبدیل می شود:\n",
        "\n",
        "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
        " ...,\n",
        " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]\n"
      ],
      "metadata": {
        "id": "mhhxeNeH5Ia_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# تبدیل لیست‌ها به آرایه‌های numpy و نرمال‌سازی\n",
        "x_train = np.array(x_train).reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "x_test = np.array(x_test).reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "\n",
        "\n",
        "# تبدیل برچسب‌ها به فرمت one-hot\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n"
      ],
      "metadata": {
        "id": "XKjn3bBzv2nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ایجاد شبکه عصبی\n",
        "\n",
        "تابع models.Sequential() یک مدل شبکه عصبی ترتیبی ایجاد می کند. پارامتر input_shape شکل ورودی شبکه عصبی را مشخص می کند. در این مورد، شکل ورودی (160, 160, 1) است، زیرا تصاویر ورودی دارای ابعاد 160 در 160 پیکسل و تک کاناله هستند (تصاویر سیاه و سفید).\n",
        "\n",
        "بدنه شبکه عصبی از یک سری لایه ها تشکیل شده است. هر لایه یک عمل خاصی را روی ورودی خود انجام می دهد و خروجی خود را به لایه بعدی ارسال می کند.\n",
        "\n",
        "لایه های استفاده شده در این شبکه عصبی عبارتند از:\n",
        "\n",
        "** لایه کانولوشن (Conv2D)**: این لایه ویژگی ها را از تصاویر ورودی استخراج می کند.\n",
        "لایه استخرش (Pooling2D): این لایه ابعاد تصاویر را کاهش می دهد و در عین حال ویژگی های مهم را حفظ می کند.\n",
        "لایه صاف (Flatten): این لایه ورودی را به یک بردار تبدیل می کند.\n",
        "لایه متصل (Dense): این لایه یک تبدیل خطی را روی ورودی خود انجام می دهد.\n",
        "آموزش شبکه عصبی\n",
        "\n",
        "تابع model.compile() کامپایلر مدل را با مشخص کردن تابع بهینه ساز، تابع زیان و معیارهای ارزیابی تنظیم می کند.\n",
        "\n",
        "تابع model.fit() مدل را روی داده های آموزش آموزش می دهد. پارامتر epochs تعداد دفعاتی را که مدل روی داده های آموزش تکرار می شود مشخص می کند.\n",
        "\n",
        "ارزیابی شبکه عصبی\n",
        "\n",
        "تابع model.evaluate() عملکرد مدل را روی داده های تست ارزیابی می کند. پارامتر verbose=0 باعث می شود که تابع هیچ خروجی چاپ نکند.\n",
        "\n"
      ],
      "metadata": {
        "id": "iLuDB-kI52jw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "amXVCwWxFABl",
        "outputId": "4f54e8dd-685f-474e-8f16-72c360cddf13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df9a1c4a-1c8d-4043-b8fa-426a019ede8e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-df9a1c4a-1c8d-4043-b8fa-426a019ede8e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading fingerprint-dataset-for-fvc2000-db4-b.zip to /content\n",
            "100% 25.9M/25.9M [00:01<00:00, 21.5MB/s]\n",
            "100% 25.9M/25.9M [00:01<00:00, 14.0MB/s]\n",
            "Number of training images: 800\n",
            "Shape of the first training image: (160, 160)\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 31s 1s/step - loss: 3.4536 - accuracy: 0.0950\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 30s 1s/step - loss: 2.3020 - accuracy: 0.1075\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 30s 1s/step - loss: 2.2813 - accuracy: 0.1650\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 30s 1s/step - loss: 2.0426 - accuracy: 0.3225\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 30s 1s/step - loss: 1.3363 - accuracy: 0.5888\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.8474 - accuracy: 0.7312\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 30s 1s/step - loss: 0.6008 - accuracy: 0.8150\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.4218 - accuracy: 0.9000\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.2486 - accuracy: 0.9638\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 31s 1s/step - loss: 0.1665 - accuracy: 0.9750\n",
            "Test loss: 1.0990928411483765\n",
            "Test accuracy: 0.6000000238418579\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-373881644fe7>\u001b[0m in \u001b[0;36m<cell line: 114>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m# ثبت اثر انگشت\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FingerPrintOriginal.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mregister_fingerprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m# احراز هویت اثر انگشت\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-373881644fe7>\u001b[0m in \u001b[0;36mregister_fingerprint\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# پیش بینی ویژگی‌های اثر انگشت\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m# ذخیره ویژگی‌ها\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 160, 160, 1), found shape=(None, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ایجاد شبکه عصبی\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(160, 160, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "\n",
        "# آموزش شبکه عصبی\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# ارزیابی شبکه عصبی\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib\n",
        "import joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok9m1r5Qy5mK",
        "outputId": "f9f03b42-b36e-4b1e-f39a-8c355b2cfd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ثبت اثر انگشت\n",
        "\n",
        "تابع register_fingerprint() یک اثر انگشت جدید را ثبت می کند. این تابع ابتدا تصویر اثر انگشت را پیش پردازش می کند و آن را به فرمت مناسب برای مدل شبکه عصبی تبدیل می کند. سپس، ویژگی های اثر انگشت را با استفاده از مدل شبکه عصبی پیش بینی می کند. در نهایت، ویژگی های اثر انگشت را ذخیره می کند.\n",
        "\n",
        "مراحل ثبت اثر انگشت:\n",
        "\n",
        "پیش پردازش تصویر:\n",
        "\n",
        "تصویر را به حالت سیاه و سفید تبدیل کنید.\n",
        "تصویر را به اندازه 160 در 160 پیکسل تغییر اندازه دهید.\n",
        "تصویر را به یک آرایه NumPy با شکل (-1, 160, 160, 1) تبدیل کنید.\n",
        "تصویر را نرمال کنید تا تمام مقادیر آن بین 0 و 1 قرار گیرند.\n",
        "پیش بینی ویژگی های اثر انگشت:\n",
        "\n",
        "ویژگی های اثر انگشت را با استفاده از مدل شبکه عصبی پیش بینی کنید.\n",
        "ویژگی های اثر انگشت را به یک بردار تبدیل کنید.\n",
        "ذخیره ویژگی های اثر انگشت:\n",
        "\n",
        "ویژگی های اثر انگشت را در یک فایل با فرمت pickle ذخیره کنید."
      ],
      "metadata": {
        "id": "jAL6QKg-58kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ثبت اثر انگشت\n",
        "def register_fingerprint(image):\n",
        "    # پیش پردازش تصویر\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = cv2.resize(image, (160, 160))\n",
        "    image = image.reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "\n",
        "    # پیش بینی ویژگی‌های اثر انگشت\n",
        "    features = model.predict(image)\n",
        "\n",
        "    # ذخیره ویژگی‌ها\n",
        "    features = features.flatten()\n",
        "    with open('fingerprint_features.pickle', 'wb') as f:\n",
        "        joblib.dump(features, f)\n",
        "\n",
        "# احراز هویت اثر انگشت\n",
        "def authenticate_fingerprint(image):\n",
        "    # پیش پردازش تصویر\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = cv2.resize(image, (160, 160))\n",
        "    image = image.reshape(-1, 160, 160, 1).astype('float32') / 255.0\n",
        "\n",
        "    # پیش بینی ویژگی‌های اثر انگشت\n",
        "    features = model.predict(image)\n",
        "\n",
        "    # مقایسه ویژگی‌ها\n",
        "    with open('fingerprint_features.pickle', 'rb') as f:\n",
        "        known_features = joblib.load(f)\n",
        "\n",
        "    # استفاده از تابع فاصله برای مقایسه ویژگی‌ها\n",
        "    dist = np.linalg.norm(features - known_features, axis=1)\n",
        "\n",
        "    # نتیجه احراز هویت\n",
        "    if dist < 0.01:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfribNlhyDKD",
        "outputId": "3ed9ec2d-2153-41ce-c952-b9eba3bca4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "خط اول تصویر `FingerPrintOriginal.jpg` را در متغیر `image` ذخیره می کند. خط دوم اثر انگشت را با استفاده از تابع `register_fingerprint()` ثبت می کند. خط سوم تصویر `FingerPrintOriginal.jpg` را دوباره در متغیر `image` ذخیره می کند. خط چهارم اثر انگشت را با استفاده از تابع `authenticate_fingerprint()` احراز هویت می کند و نتیجه را در متغیر `is_authenticated` ذخیره می کند. خط پنجم متغیر `is_authenticated` را چاپ می کند.\n",
        "\n",
        "اگر اثر انگشت معتبر باشد، خروجی کد شما `True` خواهد بود. در غیر این صورت، خروجی کد شما `False` خواهد بود.\n",
        "\n",
        "برای اجرای این کد، ابتدا باید کتابخانه های `cv2` و `joblib` را نصب کنید. سپس، می توانید کد را در یک فایل پایتون با پسوند `.py` ذخیره کنید و آن را با استفاده از کامند زیر اجرا کنید:\n",
        "\n",
        "```\n",
        "python fingerprint_authentication.py\n",
        "```\n",
        "\n",
        "اگر اثر انگشت معتبر باشد، خروجی کد به صورت زیر خواهد بود:\n",
        "\n",
        "```\n",
        "True\n",
        "```\n",
        "\n",
        "در غیر این صورت، خروجی کد به صورت زیر خواهد بود:\n",
        "\n",
        "```\n",
        "False\n",
        "```"
      ],
      "metadata": {
        "id": "TTjGywJj6Jzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ثبت اثر انگشت\n",
        "image = cv2.imread('FingerPrintOriginal.jpg')\n",
        "register_fingerprint(image)\n",
        "\n",
        "# احراز هویت اثر انگشت\n",
        "image = cv2.imread('FingerPrintOriginal.jpg')\n",
        "is_authenticated = authenticate_fingerprint(image)\n",
        "print(is_authenticated)\n"
      ],
      "metadata": {
        "id": "1n-10Ah7wQ5h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}